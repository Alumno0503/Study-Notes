{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Text to image literature（YYT from HKU library）\n",
    "\n",
    "## Below is some study notes for Text to image literatures.\n",
    "\n",
    "Here are titles of them:\n",
    "\n",
    "1、High-Resolution Image Synthesis with Latent Diffusion Models\n",
    "\n",
    "2、Adding Conditional Control to Text-to-Image Diffusion Models\n",
    "\n",
    "3、IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models\n",
    "\n",
    "4、Conceptrol: Concept Control of Zero-shot Personalized Image Generation\n",
    "\n",
    "5、Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs\n",
    "\n",
    "6、Training-Free Multi-Concept Image Generation and Editing With Rectified Flow Transformers\n",
    "\n",
    "7、MS-Diffusion: Multi-subject Zero-shot Image Personalization with Layout Guidance\n",
    "\n",
    "8、CONTEXTGEN: CONTEXTUAL LAYOUT ANCHORING FOR IDENTITY-CONSISTENT MULTI-INSTANCE GENERATION\n",
    "\n",
    "9、ANYMS: BOTTOM-UP ATTENTION DECOUPLING FOR LAYOUT-GUIDED AND TRAINING-FREE MULTISUBJECT CUSTOMIZATION\n",
    "\n",
    "10、ICAS: IP-Adapter and ControlNet-Based Attention Structure for Multi-Subject Style Transfer Optimization\n",
    "\n",
    "11、MUSE: Multi-Subject Unified Synthesis via Explicit Layout Semantic Expansion\n",
    "\n",
    "12、Stitch: Training-Free Position Control in Multimodal Diffusion Transformers\n",
    "\n",
    "13、Towards Transformer-Based Aligned Generation with Self-Coherence Guidance\n",
    "\n",
    "14、Isolated Diffusion: Optimizing Multi-Concept Text-to-Image Generation Training-Freely with Isolated Diffusion Guidance\n",
    "\n",
    "15、Resolving Multi-Condition Confusion for Finetuning-Free Personalized Image Generation\n",
    "\n"
   ],
   "id": "8a77807f92f26ee",
   "attachments": {
    "0a8c354b-3555-421e-bf09-45da69fda3d2.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhMAAADaCAIAAACTuVcmAAABZ0lEQVR4Xu3BAQ0AAADCoPdPbQ8HFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHwbTa8AAc0q4BQAAAAASUVORK5CYII="
    },
    "dc0dc621-c4c4-4d59-a67a-f825c5674b2d.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhMAAADaCAIAAACTuVcmAAABZ0lEQVR4Xu3BAQ0AAADCoPdPbQ8HFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHwbTa8AAc0q4BQAAAAASUVORK5CYII="
    }
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## High-Resolution Image Synthesis with Latent Diffusion Models\n",
    "- 作者机构与年份：Robin Rombach, Andreas Blattmann, Ludwig Maximilian University of Munich & IWR, Heidelberg University, Germany, CVPR, 2022\n",
    "- 研究背景/动机motivation：\n",
    "- 当前已有研究回顾（黄色标注）：\n",
    "- 当前存在的问题或空白：\n",
    "- 文章提出的方法/模型/原理：\n",
    "- 为什么要采用这个方法？和别人的方法有何区别，是怎么进行对比的？差距有多大？\n",
    "- 成果和结论（从哪些指标体现成果、SOTA?）：\n",
    "- 这篇文章主要的图和表（如流程图、算法图、实验的重要图表等）\n",
    "- 创新点：\n",
    "- 备注："
   ],
   "id": "29a6de0342bbd2fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Adding Conditional Control to Text-to-Image Diffusion Models\n",
    "- 作者机构与年份：\n",
    "- 研究背景/动机motivation：\n",
    "- 当前已有研究回顾（黄色标注）：\n",
    "- 当前存在的问题或空白：\n",
    "- 文章提出的方法：\n",
    "- 为什么要采用这个方法？和别人的方法有何区别，是怎么进行对比的？差距有多大？\n",
    "- 成果和结论（从哪些指标体现成果、SOTA?）：\n",
    "- 这篇文章主要的图和表（如流程图、算法图、实验的重要图表等）\n",
    "- 创新点：\n",
    "- 备注："
   ],
   "id": "9a9fc6f554cd39c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models\n",
    "- 作者机构与年份：\n",
    "- 研究背景/动机motivation：\n",
    "- 当前已有研究回顾（黄色标注）：\n",
    "- 当前存在的问题或空白：\n",
    "- 文章提出的方法：\n",
    "- 为什么要采用这个方法？和别人的方法有何区别，是怎么进行对比的？差距有多大？\n",
    "- 成果和结论（从哪些指标体现成果、SOTA?）：\n",
    "- 这篇文章主要的图和表（如流程图、算法图、实验的重要图表等）\n",
    "- 创新点：\n",
    "- 备注："
   ],
   "id": "977fc6430de15b85"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conceptrol: Concept Control of Zero-shot Personalized Image Generation\n",
    "- 作者机构与年份：\n",
    "- 研究背景/动机motivation：\n",
    "- 当前已有研究回顾（黄色标注）：\n",
    "- 当前存在的问题或空白：\n",
    "- 文章提出的方法：\n",
    "- 为什么要采用这个方法？和别人的方法有何区别，是怎么进行对比的？差距有多大？\n",
    "- 成果和结论（从哪些指标体现成果、SOTA?）：\n",
    "- 这篇文章主要的图和表（如流程图、算法图、实验的重要图表等）\n",
    "- 创新点：\n",
    "- 备注："
   ],
   "id": "5884db2753547c49"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs\n",
    "- 作者机构与年份：\n",
    "- 研究背景/动机motivation：\n",
    "- 当前已有研究回顾（黄色标注）：\n",
    "- 当前存在的问题或空白：\n",
    "- 文章提出的方法：\n",
    "- 为什么要采用这个方法？和别人的方法有何区别，是怎么进行对比的？差距有多大？\n",
    "- 成果和结论（从哪些指标体现成果、SOTA?）：\n",
    "- 这篇文章主要的图和表（如流程图、算法图、实验的重要图表等）\n",
    "- 创新点：\n",
    "- 备注："
   ],
   "id": "e43f9311ccd6f231"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## LoRAShop: Training-Free Multi-Concept Image Generation and Editing With Rectified Flow Transformers\n",
    "- 作者机构与年份：\n",
    "- 研究背景/动机motivation：\n",
    "- 当前已有研究回顾（黄色标注）：\n",
    "- 当前存在的问题或空白：\n",
    "- 文章提出的方法：\n",
    "- 为什么要采用这个方法？和别人的方法有何区别，是怎么进行对比的？差距有多大？\n",
    "- 成果和结论（从哪些指标体现成果、SOTA?）：\n",
    "- 这篇文章主要的图和表（如流程图、算法图、实验的重要图表等）\n",
    "- 创新点：\n",
    "- 备注："
   ],
   "id": "3d08a8e9ce20e447"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## MS-Diffusion: Multi-subject Zero-shot Image Personalization with Layout Guidance\n",
    "- 作者机构与年份：\n",
    "- 研究背景/动机motivation：\n",
    "- 当前已有研究回顾（黄色标注）：\n",
    "- 当前存在的问题或空白：\n",
    "- 文章提出的方法：\n",
    "- 为什么要采用这个方法？和别人的方法有何区别，是怎么进行对比的？差距有多大？\n",
    "- 成果和结论（从哪些指标体现成果、SOTA?）：\n",
    "- 这篇文章主要的图和表（如流程图、算法图、实验的重要图表等）\n",
    "- 创新点：\n",
    "- 备注："
   ],
   "id": "4f8e449e4d67fbba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
